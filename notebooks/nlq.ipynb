{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer # For extracting n-grams from a sentence\n",
    "import spacy\n",
    "import spacy_transformers\n",
    "from sentence_transformers import util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = [\n",
    "    \"For United Kingdom, Item Type with the highest Total Revenue\", \n",
    "    \"Country with the highest monthly percentage decline in Total Profit in the last 3 months\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
      "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "Collecting en-core-web-sm==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6 MB)\n",
      "     |████████████████████████████████| 13.6 MB 4.0 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from en-core-web-sm==3.1.0) (3.1.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.11)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.0)\n",
      "Requirement already satisfied: jinja2 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (21.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.7.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.62.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.26.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.6)\n",
      "Requirement already satisfied: setuptools in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (58.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.21.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.1)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.10.0.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2021.10.8)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# !python -m spacy download en_core_web_trf\n",
    "nlp = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service -> NOUN -> O -> \n",
      "delivery -> NOUN -> O -> \n",
      "head -> NOUN -> O -> \n",
      "ta -> INTJ -> O -> \n",
      "name -> NOUN -> O -> \n"
     ]
    }
   ],
   "source": [
    "word = \"service_delivery_head_ta_name\"\n",
    "\n",
    "word_split = word.split(\"_\")\n",
    "\n",
    "for split_word in word_split:\n",
    "    for token in nlp(split_word):\n",
    "        print(f\"{token.text} -> {token.pos_} -> {token.ent_iob_} -> {token.ent_type_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organization\n"
     ]
    }
   ],
   "source": [
    "word = \"organization\"\n",
    "\n",
    "# word_split = word.split(\"_\")\n",
    "\n",
    "# for split_word in word_split:\n",
    "for token in nlp(word):\n",
    "    print(f\"{token.lemma_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For -> ADP -> \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.token.Token' object has no attribute 'tensors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20516/3230918657.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;31m# if token.pos_ == \"NOUN\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{token.text} -> {token.pos_} -> {token.ent_type_}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'spacy.tokens.token.Token' object has no attribute 'tensors'"
     ]
    }
   ],
   "source": [
    "for i in range(len(input_list)):\n",
    "    for token in nlp(input_list[i]):\n",
    "        # if token.pos_ == \"NOUN\":\n",
    "        print(f\"{token.text} -> {token.pos_} -> {token.ent_type_}\")\n",
    "    print(\"---------\")\n",
    "\n",
    "# example = \"To take us through this results of the quarter and answer your question, we have with us the from the top \\\n",
    "# Management of Heranba, Mr. R. K. Shetty - Managing Director; Mr. Raunak Shetty - Executive Director, and \\\n",
    "# Mr. Raj Kumar Bafna - Chief Financial Officer.\"\n",
    "\n",
    "# for token_ent in nlp(input_list[0]).ents:\n",
    "#     print(f\"{token_ent.text} -> {token_ent.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9728014]]\n"
     ]
    }
   ],
   "source": [
    "import spacy_transformers\n",
    "from sentence_transformers import util\n",
    "\n",
    "\n",
    "for token in nlp.pipe([input_list[0]]):\n",
    "    a = token._.trf_data.tensors[-1]\n",
    "\n",
    "for token in nlp.pipe([input_list[1]]):\n",
    "    b = token._.trf_data.tensors[-1]\n",
    "    \n",
    "print(util.cos_sim(a, b).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens Country with the highest monthly percentage decline in Total Profit in the last 3 months\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>POS</th>\n",
       "      <th>ENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Country</td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>with</td>\n",
       "      <td>ADP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>highest</td>\n",
       "      <td>ADJ</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>monthly</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>percentage</td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>decline</td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Total</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Profit</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>last</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>NUM</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>months</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Text    POS   ENT\n",
       "0      Country   NOUN      \n",
       "1         with    ADP      \n",
       "2          the    DET      \n",
       "3      highest    ADJ      \n",
       "4      monthly    ADJ  DATE\n",
       "5   percentage   NOUN      \n",
       "6      decline   NOUN      \n",
       "7           in    ADP      \n",
       "8        Total    ADJ   ORG\n",
       "9       Profit  PROPN   ORG\n",
       "10          in    ADP      \n",
       "11         the    DET  DATE\n",
       "12        last    ADJ  DATE\n",
       "13           3    NUM  DATE\n",
       "14      months   NOUN  DATE"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Infer numbers using POS tags for conversion to character strings\n",
    "corpus_tokens = nlp(input_list[1])\n",
    "print('tokens', corpus_tokens)\n",
    "col_names = ['Text', 'POS', 'ENT']\n",
    "output_df = pd.DataFrame([], columns = col_names)\n",
    "\n",
    "for token in corpus_tokens:\n",
    "    inlist = pd.DataFrame([[token.text, token.pos_, token.ent_type_]], columns=col_names)\n",
    "    output_df = pd.concat([output_df, inlist], ignore_index=True)\n",
    "\n",
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"../../../datasets/ALKEM REPORT.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DIVISION', 'GEOGRAPHY', 'MARKET', 'BRANDS', 'COMPANY', 'LAUNCH DATE',\n",
       "       'CAGR % SEP 19', 'EVOLUTION INDEX SEP 19', 'RANK MAT SEP 15',\n",
       "       'RANK MAT SEP 16', 'RANK MAT SEP 17', 'RANK MAT SEP 18',\n",
       "       'RANK MAT SEP 19', 'VAL MAT SEP 15', 'VAL MAT SEP 16', 'VAL MAT SEP 17',\n",
       "       'VAL MAT SEP 18', 'VAL MAT SEP 19', 'VAL MS% MAT SEP 15',\n",
       "       'VAL MS% MAT SEP 16', 'VAL MS% MAT SEP 17', 'VAL MS% MAT SEP 18',\n",
       "       'VAL MS% MAT SEP 19', 'VAL GR% MAT SEP 16', 'VAL GR% MAT SEP 17',\n",
       "       'VAL GR% MAT SEP 18', 'VAL GR% MAT SEP 19'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aum/Desktop/projects/nlp/nlp_env/lib/python3.9/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word = \"Brands\"\n",
    "for token in nlp(word):\n",
    "    print(token.ent_type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIVISION -> O -> \n",
      "----\n",
      "GEOGRAPHY -> O -> \n",
      "----\n",
      "MARKET -> O -> \n",
      "----\n",
      "BRANDS -> O -> \n",
      "----\n",
      "COMPANY -> O -> \n",
      "----\n",
      "LAUNCH -> O -> \n",
      "DATE -> O -> \n",
      "----\n",
      "CAGR -> O -> \n",
      "% -> O -> \n",
      "SEP -> O -> \n",
      "19 -> B -> CARDINAL\n",
      "----\n",
      "EVOLUTION -> O -> \n",
      "INDEX -> O -> \n",
      "SEP -> O -> \n",
      "19 -> B -> CARDINAL\n",
      "----\n",
      "RANK -> O -> \n",
      "MAT -> O -> \n",
      "SEP -> O -> \n",
      "15 -> B -> CARDINAL\n",
      "----\n",
      "RANK -> O -> \n",
      "MAT -> O -> \n",
      "SEP -> O -> \n",
      "16 -> B -> CARDINAL\n",
      "----\n",
      "RANK -> O -> \n",
      "MAT -> O -> \n",
      "SEP -> O -> \n",
      "17 -> B -> CARDINAL\n",
      "----\n",
      "RANK -> O -> \n",
      "MAT -> O -> \n",
      "SEP -> O -> \n",
      "18 -> B -> CARDINAL\n",
      "----\n",
      "RANK -> O -> \n",
      "MAT -> O -> \n",
      "SEP -> O -> \n",
      "19 -> B -> CARDINAL\n",
      "----\n",
      "VAL -> O -> \n",
      "MAT -> O -> \n",
      "SEP -> O -> \n",
      "15 -> B -> CARDINAL\n",
      "----\n",
      "VAL -> O -> \n",
      "MAT -> O -> \n",
      "SEP -> O -> \n",
      "16 -> B -> CARDINAL\n",
      "----\n",
      "VAL -> O -> \n",
      "MAT -> O -> \n",
      "SEP -> O -> \n",
      "17 -> B -> CARDINAL\n",
      "----\n",
      "VAL -> O -> \n",
      "MAT -> O -> \n",
      "SEP -> O -> \n",
      "18 -> B -> CARDINAL\n",
      "----\n",
      "VAL -> O -> \n",
      "MAT -> O -> \n",
      "SEP -> O -> \n",
      "19 -> B -> CARDINAL\n",
      "----\n",
      "VAL -> O -> \n",
      "MS% -> O -> \n",
      "MAT -> O -> \n",
      "SEP -> O -> \n",
      "15 -> B -> CARDINAL\n",
      "----\n",
      "VAL -> O -> \n",
      "MS% -> O -> \n",
      "MAT -> O -> \n",
      "SEP -> O -> \n",
      "16 -> B -> CARDINAL\n",
      "----\n",
      "VAL -> O -> \n",
      "MS% -> O -> \n",
      "MAT -> O -> \n",
      "SEP -> O -> \n",
      "17 -> B -> CARDINAL\n",
      "----\n",
      "VAL -> O -> \n",
      "MS% -> O -> \n",
      "MAT -> O -> \n",
      "SEP -> O -> \n",
      "18 -> B -> CARDINAL\n",
      "----\n",
      "VAL -> O -> \n",
      "MS% -> O -> \n",
      "MAT -> O -> \n",
      "SEP -> O -> \n",
      "19 -> B -> CARDINAL\n",
      "----\n",
      "VAL -> O -> \n",
      "GR% -> O -> \n",
      "MAT -> O -> \n",
      "SEP -> O -> \n",
      "16 -> B -> CARDINAL\n",
      "----\n",
      "VAL -> O -> \n",
      "GR% -> O -> \n",
      "MAT -> O -> \n",
      "SEP -> O -> \n",
      "17 -> B -> CARDINAL\n",
      "----\n",
      "VAL -> O -> \n",
      "GR% -> O -> \n",
      "MAT -> O -> \n",
      "SEP -> O -> \n",
      "18 -> B -> CARDINAL\n",
      "----\n",
      "VAL -> O -> \n",
      "GR% -> O -> \n",
      "MAT -> O -> \n",
      "SEP -> O -> \n",
      "19 -> B -> CARDINAL\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for word in data.columns:\n",
    "    for token in nlp(word):\n",
    "        print(f\"{token.text} -> {token.ent_iob_} -> {token.ent_type_}\")\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check BERT Embeddings"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3502c2d8a44f1d370a9f7e349ee408832b67c21c31bd8924b7b4cde15de44893"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
